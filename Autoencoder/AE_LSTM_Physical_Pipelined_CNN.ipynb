{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(10)\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(10)\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau,EarlyStopping\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In physical space use 'raw_train.reshape(-1,121,281)' to visualize original\n",
    "num_snapshots = 12564\n",
    "#directory = '/lcrc/project/AIEADA-2/era5_data/full_data/snapshots/'\n",
    "directory = '/lus/grand/projects/datascience/bethanyl/AIEADA/snapshots/'\n",
    "\n",
    "#var_list = [raw_train_z500,\n",
    "#            raw_train_u250,raw_train_v250,raw_train_t250,\n",
    "#            raw_train_u850,raw_train_v850,raw_train_t850,\n",
    "#            raw_train_blh,raw_train_tcwv]\n",
    "input_window = 14\n",
    "output_window = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_npy_file(file_path):\n",
    "    file_path_string = bytes.decode(file_path.numpy())\n",
    "    data = np.load(file_path_string)\n",
    "    return data.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_function(file_path):\n",
    "    #example = tf.py_function(load_file_npy, inp=file_path, Tout=tf.float32)\n",
    "    example = tf.py_function(read_npy_file, [file_path], tf.float32)\n",
    "    # example has shape 21, 121, 281\n",
    "    \n",
    "    #example = tf.py_function(np.load, file_path, tf.string)\n",
    "    #tf.print(file_path)\n",
    "    #example = tf.io.read_file(file_path)\n",
    "    #example = tf.io.decode_raw(example, tf.float32)\n",
    "    print(example)\n",
    "    input_window = 14\n",
    "    input_data = example[:input_window,:,:]\n",
    "    output_data = example[input_window:,:,:]\n",
    "    # NOTE: when add LSTM part, switch output to this commented out line\n",
    "    #return input_data, (output_data, input_data)\n",
    "    return input_data, input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset(batch_size):\n",
    "    dataset_dir = directory + 'split_examples/train_data_z500_2d/'\n",
    "    filelist = glob.glob(dataset_dir + '*.npy')\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices(filelist)\n",
    "    shuffle_buffer = 6000\n",
    "    train_dataset = train_dataset.shuffle(shuffle_buffer,reshuffle_each_iteration=True)\n",
    "    train_dataset = train_dataset.map(parse_function, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    #train_dataset = train_dataset.map(\n",
    "    #    lambda item: tuple(tf.py_function(read_npy_file, [item], [tf.float32,])))\n",
    "    train_dataset = train_dataset.batch(batch_size)\n",
    "    train_dataset = train_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "    \n",
    "    return train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = np.load(directory + 'split_examples/train_data_z500_2d/example_151.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21, 121, 281)\n",
      "float32\n"
     ]
    }
   ],
   "source": [
    "print(example.shape)\n",
    "print(example.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"EagerPyFunc:0\", dtype=float32, device=/job:localhost/replica:0/task:0)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "train_dataset = build_dataset(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat = example.shape[1]\n",
    "long = example.shape[2]\n",
    "\n",
    "encode_dim = 180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: [None, 14, 121, 281, 1]\n",
      "AE Encoded shape: [None, 14, 180]\n",
      "AE Output shape: [None, 14, 121, 281, 1]\n"
     ]
    }
   ],
   "source": [
    "ff_dim = 100  # Hidden layer size in feed forward network inside transformer\n",
    "dropout_rate = 0.0\n",
    "\n",
    "inputs = layers.Input(shape=(input_window,lat,long,1)) # (None, 14, 121, 281)\n",
    "ae_encoding_layers = []\n",
    "# TimeDistributed will apply the same layer to each snapshot in time (same weights)\n",
    "# https://keras.io/api/layers/recurrent_layers/time_distributed/\n",
    "ae_encoding_layers.append(layers.TimeDistributed(layers.Conv2D(filters=50, kernel_size=(3,3), strides=(1,1),activation='elu',padding='same'))) # (None, 14, 122, 282, 50)\n",
    "ae_encoding_layers.append(layers.TimeDistributed(layers.MaxPooling2D((2,2),padding='same'))) # (None, 14, 61, 141, 50)\n",
    "ae_encoding_layers.append(layers.TimeDistributed(layers.Conv2D(filters=25, kernel_size=(3,3), strides=(1,1),activation='elu',padding='same'))) # (None, 14, 62, 142, 25)\n",
    "ae_encoding_layers.append(layers.TimeDistributed(layers.MaxPooling2D((2,2),padding='same'))) # (None, 14, 31, 71, 25)\n",
    "ae_encoding_layers.append(layers.TimeDistributed(layers.ZeroPadding2D(padding=((1,0),(1,0)))))\n",
    "ae_encoding_layers.append(layers.TimeDistributed(layers.Conv2D(filters=12, kernel_size=(3,3), strides=(1,1),activation='elu',padding='same'))) # (None, 14, 31, 71, 12)\n",
    "ae_encoding_layers.append(layers.TimeDistributed(layers.MaxPooling2D((2,3),padding='same'))) # (None, 14, 16, 24, 12)\n",
    "ae_encoding_layers.append(layers.TimeDistributed(layers.Conv2D(filters=6, kernel_size=(3,3), strides=(1,1),activation='elu',padding='same'))) # (None, 14, 16, 24, 6) \n",
    "ae_encoding_layers.append(layers.TimeDistributed(layers.MaxPooling2D((2,3),padding='same'))) # [None, 14, 8, 8, 6]\n",
    "ae_encoding_layers.append(layers.TimeDistributed(layers.Flatten())) # [None, 14, 384]\n",
    "ae_encoding_layers.append(layers.TimeDistributed(layers.Dense(encode_dim, activation=None))) # [None, 14, 180]\n",
    "\n",
    "    \n",
    "# decoder for reconstruction\n",
    "ae_decoding_layers = []\n",
    "ae_decoding_layers.append(layers.TimeDistributed(layers.Dense(384, activation='elu'))) # (None, 14, 384) \n",
    "ae_decoding_layers.append(layers.TimeDistributed(layers.Reshape((8, 8, 6)))) #  (None, 14, 8, 8, 6)\n",
    "ae_decoding_layers.append(layers.TimeDistributed(layers.Conv2D(filters=6, kernel_size=(3,3), strides=(1,1),activation='elu',padding='same'))) # (None, 14, 8, 8, 6)\n",
    "ae_decoding_layers.append(layers.TimeDistributed(layers.UpSampling2D((2,3)))) # (None, 14, 16, 24, 6)\n",
    "ae_decoding_layers.append(layers.TimeDistributed(layers.Conv2D(filters=12, kernel_size=(3,3), strides=(1,1),activation='elu',padding='same'))) # (None, 14, 16, 24, 12)\n",
    "ae_decoding_layers.append(layers.TimeDistributed(layers.UpSampling2D((2,3)))) # (None, 14, 32, 72, 12) \n",
    "ae_decoding_layers.append(layers.TimeDistributed(layers.Cropping2D(cropping=((1, 0), (1, 0))))) # (None, 14, 31, 71, 12) \n",
    "ae_decoding_layers.append(layers.TimeDistributed(layers.Conv2D(filters=25, kernel_size=(3,3), strides=(1,1),activation='elu',padding='same'))) # (None, 14, 31, 71, 25) \n",
    "ae_decoding_layers.append(layers.TimeDistributed(layers.UpSampling2D((2,2)))) # (None, 14, 62, 142, 25) \n",
    "ae_decoding_layers.append(layers.TimeDistributed(layers.Conv2D(filters=50, kernel_size=(3,3), strides=(1,1),activation='elu',padding='same'))) # (None, 14, 62, 142, 50)\n",
    "ae_decoding_layers.append(layers.TimeDistributed(layers.Cropping2D(cropping=((1, 0), (1, 0))))) # (None, 14, 61, 141, 50) \n",
    "ae_decoding_layers.append(layers.TimeDistributed(layers.UpSampling2D((2,2)))) #  (None, 14, 122, 282, 50)\n",
    "ae_decoding_layers.append(layers.TimeDistributed(layers.Cropping2D(cropping=((1, 0), (1, 0))))) #  (None, 14, 121, 281, 50)\n",
    "ae_decoding_layers.append(layers.TimeDistributed(layers.Conv2D(filters=1,kernel_size=(1,1),activation=None,padding='same'))) # (None, 14, 121, 281, 1) \n",
    "\n",
    "# NOTE: commenting out this section for now to try to just get an autoencoder\n",
    "# decoder for prediction    \n",
    "#lstm_decoding_layers = []\n",
    "#lstm_decoding_layers.append(layers.RepeatVector(output_window))\n",
    "#lstm_decoding_layers.append(layers.LSTM(100,activation='elu', return_sequences=True))\n",
    "#lstm_decoding_layers.append(layers.TimeDistributed(layers.Dense(embed_dim)))\n",
    "\n",
    "\n",
    "# Encode from physical space\n",
    "print('Input shape:',inputs.get_shape().as_list())\n",
    "\n",
    "x = inputs\n",
    "num_ae_encoder_layers = len(ae_encoding_layers)\n",
    "for i in range(num_ae_encoder_layers):\n",
    "    x = ae_encoding_layers[i](x)\n",
    "encoded = x\n",
    "\n",
    "print('AE Encoded shape:',encoded.get_shape().as_list())\n",
    "\n",
    "#preds = encoded\n",
    "#num_lstm_layers = len(lstm_layers)\n",
    "#for i in range(num_lstm_layers):\n",
    "#    preds = lstm_layers[i](preds)\n",
    "\n",
    "#print('LSTM prediction shape:',preds.get_shape().as_list())\n",
    "    \n",
    "recon = encoded\n",
    "num_ae_decoder_layers = len(ae_decoding_layers)\n",
    "for i in range(num_ae_decoder_layers):\n",
    "    recon = ae_decoding_layers[i](recon)\n",
    "    \n",
    "print('AE Output shape:',recon.get_shape().as_list())\n",
    "\n",
    "#model = tf.keras.Model(inputs=inputs, outputs=[preds,recon])\n",
    "model = tf.keras.Model(inputs=inputs, outputs=recon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "                              patience=5, min_lr=0.0001)\n",
    "early_stop = EarlyStopping(monitor='val_loss',patience=20)\n",
    "\n",
    "#model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),loss='mean_squared_error',loss_weights=[1,1])\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 14, 121, 281, 1)  0         \n",
      "                             ]                                   \n",
      "                                                                 \n",
      " time_distributed (TimeDistr  (None, 14, 121, 281, 50)  500      \n",
      " ibuted)                                                         \n",
      "                                                                 \n",
      " time_distributed_1 (TimeDis  (None, 14, 61, 141, 50)  0         \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " time_distributed_2 (TimeDis  (None, 14, 61, 141, 25)  11275     \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " time_distributed_3 (TimeDis  (None, 14, 31, 71, 25)   0         \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " time_distributed_4 (TimeDis  (None, 14, 32, 72, 25)   0         \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " time_distributed_5 (TimeDis  (None, 14, 32, 72, 12)   2712      \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " time_distributed_6 (TimeDis  (None, 14, 16, 24, 12)   0         \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " time_distributed_7 (TimeDis  (None, 14, 16, 24, 6)    654       \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " time_distributed_8 (TimeDis  (None, 14, 8, 8, 6)      0         \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " time_distributed_9 (TimeDis  (None, 14, 384)          0         \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " time_distributed_10 (TimeDi  (None, 14, 180)          69300     \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_11 (TimeDi  (None, 14, 384)          69504     \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_12 (TimeDi  (None, 14, 8, 8, 6)      0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_13 (TimeDi  (None, 14, 8, 8, 6)      330       \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_14 (TimeDi  (None, 14, 16, 24, 6)    0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_15 (TimeDi  (None, 14, 16, 24, 12)   660       \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_16 (TimeDi  (None, 14, 32, 72, 12)   0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_17 (TimeDi  (None, 14, 31, 71, 12)   0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_18 (TimeDi  (None, 14, 31, 71, 25)   2725      \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_19 (TimeDi  (None, 14, 62, 142, 25)  0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_20 (TimeDi  (None, 14, 62, 142, 50)  11300     \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_21 (TimeDi  (None, 14, 61, 141, 50)  0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_22 (TimeDi  (None, 14, 122, 282, 50)  0        \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_23 (TimeDi  (None, 14, 121, 281, 50)  0        \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_24 (TimeDi  (None, 14, 121, 281, 1)  51        \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 169,011\n",
      "Trainable params: 169,011\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-21 17:20:35.455483: W tensorflow/core/common_runtime/forward_type_inference.cc:231] Type inference failed. This indicates an invalid graph that escaped type checking. Error message: INVALID_ARGUMENT: expected compatible input types, but input 1:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_BOOL\n",
      "    }\n",
      "  }\n",
      "}\n",
      " is neither a subtype nor a supertype of the combined inputs preceding it:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_LEGACY_VARIANT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\twhile inferring type of node 'mean_squared_error/cond/output/_11'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "392/392 [==============================] - ETA: 0s - loss: 75834528.0000WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
      "392/392 [==============================] - 110s 260ms/step - loss: 75834528.0000 - lr: 0.0010\n",
      "Epoch 2/250\n",
      " 91/392 [=====>........................] - ETA: 1:16 - loss: 2083816.5000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [14]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m250\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mreduce_lr\u001b[49m\u001b[43m,\u001b[49m\u001b[43mearly_stop\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/lus/theta-fs0/software/thetagpu/conda/2022-07-01/mconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/lus/theta-fs0/software/thetagpu/conda/2022-07-01/mconda3/lib/python3.8/site-packages/keras/engine/training.py:1413\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1411\u001b[0m   context\u001b[38;5;241m.\u001b[39masync_wait()\n\u001b[1;32m   1412\u001b[0m logs \u001b[38;5;241m=\u001b[39m tmp_logs  \u001b[38;5;66;03m# No error, now safe to assign to logs.\u001b[39;00m\n\u001b[0;32m-> 1413\u001b[0m end_step \u001b[38;5;241m=\u001b[39m step \u001b[38;5;241m+\u001b[39m \u001b[43mdata_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_increment\u001b[49m\n\u001b[1;32m   1414\u001b[0m callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(end_step, logs)\n\u001b[1;32m   1415\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[0;32m/lus/theta-fs0/software/thetagpu/conda/2022-07-01/mconda3/lib/python3.8/site-packages/keras/engine/data_adapter.py:1268\u001b[0m, in \u001b[0;36mDataHandler.step_increment\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1265\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_step \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m steps_remaining\n\u001b[1;32m   1266\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_steps_per_execution\u001b[38;5;241m.\u001b[39massign(original_spe)\n\u001b[0;32m-> 1268\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m   1269\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep_increment\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1270\u001b[0m   \u001b[38;5;124;03m\"\"\"The number to increment the step for `on_batch_end` methods.\"\"\"\u001b[39;00m\n\u001b[1;32m   1271\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_step_increment\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(train_dataset,epochs=250,callbacks=[reduce_lr,early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda/2022-07-01",
   "language": "python",
   "name": "conda-2022-07-01"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
